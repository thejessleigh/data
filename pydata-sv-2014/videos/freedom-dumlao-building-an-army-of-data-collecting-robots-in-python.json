{
  "copyright_text": null,
  "description": "Sometimes the greatest challenge in working with data is getting data to work with in the first place. In this talk I'll take the audience through the process of building a toolset that can be used to launch a virtual army of data collectors that can help get large volumes of useful data quickly. (No live coding or slides full of code will be presented, we're going to deal with concepts and I'll direct the audience to a github repository with examples at the end of the talk.)\nSince it's the most widely available and a common source of valuable information, we'll focus primarily on gathering data from the web, although the principals could certainly be used to churn through other data sources as well.\nWe'll start by examining a simple web-scraper and the limitations of a singular, linear process. We'll then progress through the concepts of threading and concurrency, and all the way through multiprocessing. (Again, very little code, mostly graphics to help improve understanding of the concepts.)\nOnce we reach this point, we can discover together that there are limitations to this approach, even on super fast multi-core machines with tons of RAM. Network bottlenecks, ISP issues, and the possibility of creating an inadvertent Denial of Service Attack, not to mention the fact that you may not be able to use the computer in question while the data harvesting is going on.\nFrom here we can consider the idea of using an inexpensive virtual machine running somewhere else (such as AWS) to do our bidding and harvest data while we wait. I'll show how some very simple tools like Vagrant and Fabric can be combined to make running code on a remote machine simple.\nWe'll still have some limitations though. Moving everything to a remote machine solves some of our original problems, but in the end it's still one machine and even the most powerful machine is going to have limits.\nI'll present ways that we can spawn a network (an Army!) of virtual machines that can all work together to complete the task at hand, and have that power available to run any python code we desire.",
  "duration": 1901,
  "language": "eng",
  "recorded": "2014-05-03",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://pydata.org/sv2014/schedule/"
    },
    {
      "label": "Abstract",
      "url": "https://pydata.org/sv2014/abstracts/#190"
    },
    {
      "label": "Speaker information",
      "url": "https://pydata.org/sv2014/speakers/#259"
    }
  ],
  "speakers": ["Freedom Dumlao"],
  "tags": ["data", "data collection"],
  "thumbnail_url": "https://i.ytimg.com/vi/p7oFxz_NykQ/maxresdefault.jpg",
  "title": "Building an Army of Data Collecting Robots in Python",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=p7oFxz_NykQ"
    }
  ]
}
